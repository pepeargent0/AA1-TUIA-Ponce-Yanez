{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a62f23f-3431-4d69-bd27-d4be202d4c49",
   "metadata": {},
   "source": [
    "## TUIA - Aprendizaje Automático 1\n",
    "\n",
    "### Trabajo Práctico: Predicción de lluvia en Australia.\n",
    "\n",
    "### Integrantes:\n",
    "- Ponce, Daniel\n",
    "- Yañez, Mirian\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabeef9-e732-4a21-bd59-f842c1524b46",
   "metadata": {},
   "source": [
    "El presente informe detalla el trabajo práctico llevado a cabo para la predicción de las condiciones climáticas en Australia, centrándonos en las ciudades de Adelaide, Canberra, Cobar, Dartmoor, Melbourne, MelbourneAirport, MountGambier, Sydney y SydneyAirport. \n",
    "\n",
    "El conjunto de datos utilizado se denomina weatherAUS.csv y contiene información climática de los últimos diez años.\n",
    "\n",
    "## Variables de Interés:\n",
    "\n",
    "**RainTomorrow y RainfallTomorrow**: Estas variables representan nuestro objetivo de predicción, indicando si lloverá al día siguiente y la cantidad de lluvia, respectivamente.\n",
    "\n",
    "\"RainTomorrow\" (categórica, para un problema de clasificación)\n",
    "\n",
    "\"RainfallTomorrow\" (continua, para un problema de regresión)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a1666-32bc-428d-8346-d2f06da55f01",
   "metadata": {},
   "source": [
    "## Paquetes y Librerias"
   ]
  },
  {
   "cell_type": "code",
   "id": "173f2bf9c27c6fa0",
   "metadata": {},
   "source": [
    "!pip3 install pandas scikit-learn seaborn imblearn\n",
    "!pip3 install -U imbalanced-learn\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "485bc07e-6832-40f1-9d1f-8ef2ebcc32c8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:02.493745Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LogisticRegression, ElasticNetCV, RidgeCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, matthews_corrcoef, cohen_kappa_score, roc_auc_score, roc_curve, mean_squared_error, r2_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import uniform\n",
    "import shap\n",
    "import warnings\n",
    "import optuna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18a7ace6",
   "metadata": {},
   "source": [
    "### Función que vamos a utilizar más adelante para las métricas de regresión"
   ]
  },
  {
   "cell_type": "code",
   "id": "1daec272d64b6c84",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:02.500942Z"
    }
   },
   "source": [
    "def show_metrics_regresion(y, y_pred, title, nr_neuronal=True):\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    print(title)\n",
    "    print(\"Mean Squared Error :\", mse)\n",
    "    print(\"R-squared:\", r2)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    if nr_neuronal:\n",
    "        mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "        print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f31650b338e8db63",
   "metadata": {},
   "source": [
    "### Función para metricas adicionales de clasificación "
   ]
  },
  {
   "cell_type": "code",
   "id": "24c50b474ce1a58d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:02.507390Z"
    }
   },
   "source": [
    "def show_metrics_extras(y, y_pred, title=''):\n",
    "    balanced_accuracy = balanced_accuracy_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    mcc = matthews_corrcoef(y, y_pred)\n",
    "    kappa = cohen_kappa_score(y, y_pred)\n",
    "    print(title)\n",
    "    print(f'Especificidad: {specificity}')\n",
    "    print(\"Precisión Balanceada:\", balanced_accuracy)\n",
    "    print(\"Coeficiente de Correlación de Matthews:\", mcc)\n",
    "    print(\"Kappa: \",kappa)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2d99fbfe778148d",
   "metadata": {},
   "source": [
    "### Especificidad:\n",
    "\n",
    "La especificidad, también conocida como tasa de verdaderos negativos (TNR), mide la proporción de casos negativos reales que se identifican correctamente como negativos. Se calcula como el número de verdaderos negativos (TN) dividido por el número total de negativos (TN + FP).\n",
    "\n",
    "En otras palabras, la especificidad indica qué tan bien el modelo evita clasificar erróneamente las instancias negativas como positivas. Un valor de especificidad alto (cercano a 1) significa que el modelo es muy bueno para distinguir entre verdaderos negativos y falsos positivos.\n",
    "\n",
    "### Precisión Balanceada:\n",
    "\n",
    "La precisión balanceada, también conocida como precisión equilibrada, es una métrica diseñada específicamente para evaluar modelos de clasificación en conjuntos de datos desequilibrados. Tiene en cuenta el desequilibrio entre las clases positivas y negativas, proporcionando una evaluación más equilibrada del rendimiento del modelo.\n",
    "\n",
    "La precisión balanceada se calcula como el promedio de la sensibilidad y la especificidad, dando el mismo peso a ambas medidas. Esto es importante en conjuntos de datos desequilibrados donde centrarse únicamente en la precisión puede ser engañoso, ya que se puede lograr una alta precisión simplemente prediciendo la clase mayoritaria (incluso si eso significa clasificar incorrectamente muchas instancias de la clase minoritaria).\n",
    "\n",
    "### Coeficiente de Correlación de Matthews (MCC):\n",
    "\n",
    "El coeficiente de correlación de Matthews (MCC) es una métrica completa que considera tanto los verdaderos positivos como los verdaderos negativos, proporcionando una evaluación más robusta del rendimiento de la clasificación. Se calcula como el coeficiente de correlación entre las etiquetas de clase binarias predichas y reales.\n",
    "\n",
    "MCC varía de -1 a 1, donde 1 indica una concordancia perfecta entre las etiquetas predichas y reales, 0 indica que no hay correlación y -1 indica una discordancia completa. Un valor MCC más alto (más cercano a 1) indica un mejor rendimiento.\n",
    "\n",
    "### Kappa:\n",
    "\n",
    "Kappa, también conocido como kappa de Cohen, es una medida estadística de concordancia entre dos anotadores o clasificaciones. Tiene en cuenta la posibilidad de concordancia aleatoria, proporcionando una evaluación de concordancia más matizada que simplemente comparar el porcentaje de etiquetas coincidentes.\n",
    "\n",
    "Kappa varía de 0 a 1, donde 1 indica una concordancia perfecta, 0 indica que no hay concordancia más allá del azar y los valores negativos indican una concordancia peor que el azar. Un valor kappa más alto (más cercano a 1) indica una mejor concordancia entre las etiquetas predichas y reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd04e7-45dc-49f8-b05b-0ec0eaa7ffc7",
   "metadata": {},
   "source": [
    "## Importamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "f33f6b14-a3dc-47b1-aa75-942e8aaad034",
   "metadata": {},
   "source": [
    "file_path= 'weatherAUS.csv'\n",
    "df = pd.read_csv(file_path, sep=',')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e63b9b1b-8fac-4e8d-b0c7-9636bc899b30",
   "metadata": {},
   "source": [
    "## Filtramos por las ciudades de interés, convertimos a formato date la fecha y las ordenamos de forma ascendente\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8928b114-fd9b-47c4-8f20-0ff33e465395",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:02.851283Z"
    }
   },
   "source": [
    "ciudades = ['Adelaide', 'Canberra', 'Cobar', 'Dartmoor', 'Melbourne', 'MelbourneAirport', 'MountGambier', 'Sydney', 'SydneyAirport']\n",
    "df = df[df['Location'].isin(ciudades)]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(by='Date')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "330ac8ba7c1946a7",
   "metadata": {},
   "source": [
    "## Visualizamos la distribución de los datos por año"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b474456f7203d7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:02.878713Z"
    }
   },
   "source": [
    "df['Year'] = pd.to_datetime(df['Date']).dt.year # Creamos la columna Year para poder realizar la visualización por año\n",
    "\n",
    "# Contamos la cantidad de datos por año\n",
    "data_by_year = df['Year'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data_by_year.plot(kind='bar', color='skyblue')\n",
    "plt.title('Cantidad de datos por año (2007-2017)')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Cantidad de datos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "df = df.drop(columns=['Year']) # Eliminamos la columna Year"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7ee2a3bc-596b-4d80-9ae9-b9fc350b4885",
   "metadata": {},
   "source": [
    "## Realizamos el split de entrenamiento y prueba \n",
    "\n",
    "Decidimos dividir el conjunto de datos de forma manual. Esta elección se debe a que posteriormente imputaremos los valores basados en la fecha. Si utilizáramos la función train_test_split, la separación sería aleatoria, lo que podría provocar una fuga de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ba04724ac11f7e8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:03.086179Z"
    }
   },
   "source": [
    "# Definimos las fechas límite para la división\n",
    "date_train_limit = pd.to_datetime('2015-10-06')\n",
    "\n",
    "# Filtramos el DataFrame para obtener los conjuntos de entrenamiento y prueba\n",
    "train = df[df['Date'] <= date_train_limit]\n",
    "test = df[df['Date'] > date_train_limit]\n",
    "\n",
    "print(f\"El conjunto de entrenamiento tiene {len(train)} registros y va hasta la fecha {date_train_limit}.\")\n",
    "print(f\"El conjunto de prueba tiene {len(test)} registros y empieza a partir de la fecha {date_train_limit}.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6cb83657-20a4-4341-85e2-5f0fe6165928",
   "metadata": {},
   "source": [
    "## Análisis descriptivo\n",
    "\n",
    "Se realizará un análisis exploratorio del conjunto de datos de entrenamiento para entender sus características principales y determinar si se requiere alguna acción para abordar datos faltantes, valores atípicos, la codificación de variables categóricas u otros procesos antes de proceder."
   ]
  },
  {
   "cell_type": "code",
   "id": "88ae449c-232d-48e2-9ace-ceb8ccbe5cdb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:03.097599Z"
    }
   },
   "source": [
    "train.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34837b49-4c97-4d44-9d9f-268783138e0a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:03.105743Z"
    }
   },
   "source": [
    "train.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed9405a5-c396-41ef-a9d8-32b6fc753ede",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:03.127167Z"
    }
   },
   "source": [
    "train.info()\n",
    "train.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be6006fd-be46-4814-b48a-1b45470f22c7",
   "metadata": {},
   "source": [
    "### **Hay un total de 22590 datos de entrenamiento, 25 columnas y se puede observar que hay datos nulos en la mayoria de las variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d465d-8e27-4f2f-a2b2-488d2e4ddb83",
   "metadata": {},
   "source": [
    "### Eliminamos la columna 'Unnamed: 0' y 'Location'\n",
    "Eliminamos la columna Location ya que vamos a considerarlas a todas como una sola"
   ]
  },
  {
   "cell_type": "code",
   "id": "c3fb1ffd-9f0b-4b31-86b0-9564964a4ec6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:03.174128Z"
    }
   },
   "source": [
    "train = train.drop(columns=['Unnamed: 0', 'Location'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fcf84609-33f6-42ea-82b3-4e8f66d3b9f7",
   "metadata": {},
   "source": [
    "### Cambiamos los valores nulos\n",
    "Debido a que tomamos las ciudades como una única localidad, decidimos reemplazar los valores faltantes por otro de la misma fecha o, en su defecto, por la más cercana."
   ]
  },
  {
   "cell_type": "code",
   "id": "b78e18e2-cc0a-4ded-aba2-c1b8cfb1d1cf",
   "metadata": {},
   "source": [
    "train.sort_values(by='Date', inplace=True)\n",
    "train.fillna(method='ffill', inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aa1597a0-b60a-43f9-9f05-c0b0e984c991",
   "metadata": {},
   "source": [
    "train.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "42a1101d24ee1cb7",
   "metadata": {},
   "source": [
    "### Eliminamos la columna Date:\n",
    "La razon es que ya no la vamos a usar, solo la usamos como criterio para el reemplazo de los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "id": "7277bfc874881b79",
   "metadata": {},
   "source": [
    "train = train.drop(columns=['Date'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ba2fa096762cc54",
   "metadata": {},
   "source": [
    "train.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb02c9aa3a8a3bd5",
   "metadata": {},
   "source": [
    "## Creación de columnas \n",
    "Con el objetivo de reducir la cantidad de columnas y mejorar la explicabilidad del modelo, decidimos agrupar las variables que representan dos momentos del día en una sola columna."
   ]
  },
  {
   "cell_type": "code",
   "id": "412d02df41374c0a",
   "metadata": {},
   "source": [
    "columns_to_aggregate = ['Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm', 'Humidity9am', \n",
    "                        'Humidity3pm', 'Cloud9am', 'Cloud3pm','WindSpeed3pm','WindSpeed9am']\n",
    "new_columns = []\n",
    "train['PressureVariation'] = train['Pressure3pm'] - train['Pressure9am']\n",
    "train['TempVariation'] = train['Temp3pm'] - train['Temp9am']\n",
    "train['HumidityVariation'] = train['Humidity3pm'] - train['Humidity9am']\n",
    "train['CloudVariation'] = train['Cloud3pm'] - train['Cloud9am']\n",
    "train['WindSpeedVariation'] = train['WindSpeed3pm'] - train['WindSpeed9am']\n",
    "train.drop(columns=columns_to_aggregate, inplace=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f664a4ede898e111",
   "metadata": {},
   "source": [
    "train.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64c5771ed05b410f",
   "metadata": {},
   "source": [
    "### Estadística descriptiva de las variables numéricas\n",
    "Examinamos medidas estadísticas, incluyendo valores mínimos, máximos, cuartiles, y medidas de centralidad como la mediana (50%) y la media."
   ]
  },
  {
   "cell_type": "code",
   "id": "2318fe48211310b3",
   "metadata": {},
   "source": [
    "train.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9fb05c43c2733b31",
   "metadata": {},
   "source": [
    "Al analizar las columnas, se percibe que tanto la media como la mediana muestran una cercanía notable, lo que sugiere una tendencia consistente en los datos. Los desvíos en la dispersión de los datos no son extremos y la distribución no presentaria una gran extensión en un boxplot.\n",
    "\n",
    "Los valores mínimos y máximos registrados estan considerablemente alejados de los valores centrales, lo cual señala la posible existencia de valores atípicos dentro del conjunto de datos.\n",
    "\n",
    "## **Bloxplot**"
   ]
  },
  {
   "cell_type": "code",
   "id": "410a8863cdfa8297",
   "metadata": {},
   "source": [
    "numeric_columns = train.select_dtypes(include=[np.float64]).columns\n",
    "\n",
    "colores = sns.color_palette('husl', n_colors=len(numeric_columns))\n",
    "\n",
    "fig, axes = plt.subplots(len(numeric_columns), 1, figsize=(15, 20), sharex=False)\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    sns.boxplot(data=train, x=col, ax=axes[i], color=colores[i], orient='h')\n",
    "    axes[i].set_title(f'Boxplot de {col}')\n",
    "    axes[i].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "03ad0396",
   "metadata": {},
   "source": [
    "Se puede observar una gran presencia de valores que parecen ser atípicos en la mayoría de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb95b665847367",
   "metadata": {},
   "source": [
    "## Histograma"
   ]
  },
  {
   "cell_type": "code",
   "id": "6199b440b274d64a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:05.175708Z"
    }
   },
   "source": [
    "numeric_columns = train.select_dtypes(include=[np.float64]).columns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(4, 5, i)\n",
    "    sns.histplot(train[column].dropna(), kde=True)\n",
    "    plt.title(f'Histograma de {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94984b033a839ed",
   "metadata": {},
   "source": [
    "Para comprender más a fondo el comportamiento de los datos, empleamos histogramas donde se puede apreciar que algunas variables exhiben una distribución más uniforme de sus valores, como es el caso de la temperatura, humedad y presión. Por otro lado, existen variables que muestran la presencia de múltiples modas en los datos y una distribución menos uniforme.\n",
    "\n",
    "Asimismo, se destaca que la variable Rainfall concentra la gran mayoría de sus datos en cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de8ec89276adcd",
   "metadata": {},
   "source": [
    "## Analizamos nuestra variable objetivo, la que queremos predecir para saber si el dataset esta balanceado o no.\n",
    "Primero convertimos las variables categóricas en numéricas"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c6632d275a577d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:14.350988Z"
    }
   },
   "source": [
    "train['RainToday'] = train['RainToday'].map({'No': 0, 'Yes': 1})\n",
    "train['RainTomorrow'] = train['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "test['RainToday'] = test['RainToday'].map({'No': 0, 'Yes': 1})\n",
    "test['RainTomorrow'] = test['RainTomorrow'].map({'No': 0, 'Yes': 1})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a83da0fc5f7fcd03",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:14.362186Z"
    }
   },
   "source": [
    "# Calculamos los porcentajes para el conjunto de entrenamiento\n",
    "train_percentages = train['RainTomorrow'].value_counts(normalize=True) * 100\n",
    "# Calculamos los porcentajes para el conjunto de prueba\n",
    "test_percentages = test['RainTomorrow'].value_counts(normalize=True) * 100\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='RainTomorrow', data=train)\n",
    "plt.title('Distribución de RainTomorrow - Train')\n",
    "for i, value in enumerate(train_percentages):\n",
    "    plt.text(i, train['RainTomorrow'].value_counts()[i], f'{value:.2f}%', ha='center')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='RainTomorrow', data=test)\n",
    "plt.title('Distribución de RainTomorrow - Test')\n",
    "for i, value in enumerate(test_percentages):\n",
    "    plt.text(i, test['RainTomorrow'].value_counts()[i], f'{value:.2f}%', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6bb4386b9d5025db",
   "metadata": {},
   "source": [
    "Se observa que tanto en el conjuntos de entrenamiento como en el de prueba hay una mayor cantidad de datos donde no llueve (0) comparado con los días que llueve (1). Esto puede hacer que el modelo tenga un sesgo muy importante al momento de predecir. Por esta razón, podemos decir que los datos no se encuentran balanceados.\n",
    "\n",
    "Podemos ver una relacion 3 a 1 aproximadamente, en este caso existe la posibilidad de balancear el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb600e7cf71a161",
   "metadata": {},
   "source": [
    "# Matriz de correlación "
   ]
  },
  {
   "cell_type": "code",
   "id": "6d5377041cc75170",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:14.623721Z"
    }
   },
   "source": [
    "numeric_columns = numeric_columns.append(pd.Index(['RainTomorrow']))\n",
    "correlation_matrix_numeric = train[numeric_columns].corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix_numeric, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e85a94310a8e3ae0",
   "metadata": {},
   "source": [
    "Podemos observar que las variables con mayor correlación positiva con RainfallTomorrow son:\n",
    "\n",
    "*   Rainfall (0.25)\n",
    "*   HumidityVariation (0.22)\n",
    "*   WindGustSpeed (0.17)\n",
    "\n",
    "Las variables con mayor correlación negativa con RainfallTomorrow son:\n",
    "*   Sunshine (-0.28)\n",
    "*   TempVariation (-0.23)\n",
    "\n",
    "Las variables con mayor correlación positiva con RainTomorrow son:\n",
    "\n",
    "*   RainfallTomorrow (0.55)\n",
    "*   HumidityVariation (0,27)\n",
    "*   Rainfall (0.24)\n",
    "*   WindGustSpeed (0,24)\n",
    "\n",
    "Las variables con mayor correlación negativa con RainTomorrow son:\n",
    "*   Sunshine (-0.37)\n",
    "*   TempVariation (-0.32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ead3cd19c6731",
   "metadata": {},
   "source": [
    "## Para poder ver las metricas de test necesitamos aplicarle los mismos cambios que se hicieron en train."
   ]
  },
  {
   "cell_type": "code",
   "id": "37f31e1aafeec8e1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.264973Z"
    }
   },
   "source": [
    "test.sort_values(by='Date', inplace=True)\n",
    "\n",
    "for column in test.columns:\n",
    "    test[column] = test[column].ffill()\n",
    "    test[column] = test[column].bfill() \n",
    "    \n",
    "columns_to_aggregate = ['Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm', 'Humidity9am', \n",
    "                        'Humidity3pm', 'Cloud9am', 'Cloud3pm','WindSpeed3pm','WindSpeed9am']\n",
    "new_columns = []\n",
    "test = test.drop(columns=['Unnamed: 0', 'Location','Date'])\n",
    "test['PressureVariation'] = test['Pressure3pm'] - test['Pressure9am']\n",
    "test['TempVariation'] = test['Temp3pm'] - test['Temp9am']\n",
    "test['HumidityVariation'] = test['Humidity3pm'] - test['Humidity9am']\n",
    "test['CloudVariation'] = test['Cloud3pm'] - test['Cloud9am']\n",
    "test['WindSpeedVariation'] = test['WindSpeed3pm'] - test['WindSpeed9am']\n",
    "test.drop(columns=columns_to_aggregate, inplace=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "722e344c8867de40",
   "metadata": {},
   "source": [
    "# Método LinearRegression\n",
    "\n",
    "Evaluamos el modelo con los datos de entrenamiento y luego con los de test"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a6d40b0f4306541",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.297234Z"
    }
   },
   "source": [
    "X_train = train.drop(['RainfallTomorrow','WindGustDir','WindDir9am','WindDir3pm','RainTomorrow'], axis=1)\n",
    "y_train = train['RainfallTomorrow']\n",
    "X_test = test.drop(['RainfallTomorrow','WindGustDir','WindDir9am','WindDir3pm','RainTomorrow'], axis=1)\n",
    "y_test = test['RainfallTomorrow']\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test, \"Métricas sobre los datos de prueba:\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2690b282",
   "metadata": {},
   "source": [
    "No se observa presencia de overfiting, podemos notar que las metricas de train y test son bastante similares\n",
    "\n",
    "El modelo de regresión lineal tiene un bajo rendimiento, con un R² alrededor de 0.17-0.19, indicando que no explica bien la variabilidad de los datos. \n",
    "\n",
    "Las métricas de error (MSE y MAE) son ligeramente mayores en los datos de prueba que en los de entrenamiento, sugiriendo una generalización razonable pero mejorable. \n",
    "\n",
    "El MAPE no es fiable debido a valores pequeños en la variable dependiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5cd15f9e8c972b",
   "metadata": {},
   "source": [
    "# Método de gradiente descendiente"
   ]
  },
  {
   "cell_type": "code",
   "id": "cf29a9663ac372c7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.359483Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    # Evitar divisiones por cero\n",
    "    y_true = np.where(y_true == 0, 1e-7, y_true)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def gradient_descent(X_train, y_train, X_test, y_test, lr, epochs):\n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "    o = X_test.shape[0]\n",
    "\n",
    "    # Poner columna de unos a las matrices X\n",
    "    X_train = np.hstack((np.ones((n, 1)), X_train))\n",
    "    X_test = np.hstack((np.ones((o, 1)), X_test))\n",
    "\n",
    "    # Inicializar pesos aleatorios\n",
    "    W = np.random.randn(m+1).reshape(m+1, 1)\n",
    "\n",
    "    train_errors = []  # Para almacenar el error de entrenamiento en cada época\n",
    "    test_errors = []   # Para almacenar el error de prueba en cada época\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Calcular predicción y error de entrenamiento\n",
    "        prediction_train = np.matmul(X_train, W)\n",
    "        error_train = y_train - prediction_train\n",
    "        train_mse = np.mean(error_train ** 2)\n",
    "        train_errors.append(train_mse)\n",
    "\n",
    "        # Calcular predicción y error de prueba\n",
    "        prediction_test = np.matmul(X_test, W)\n",
    "        error_test = y_test - prediction_test\n",
    "        test_mse = np.mean(error_test ** 2)\n",
    "        test_errors.append(test_mse)\n",
    "\n",
    "        # Calcular el gradiente y actualizar pesos\n",
    "        grad_sum = np.sum(error_train * X_train, axis=0)\n",
    "        grad_mul = -2/n * grad_sum  # 1xm\n",
    "        gradient = np.transpose(grad_mul).reshape(-1, 1)  # mx1\n",
    "\n",
    "        W = W - (lr * gradient)\n",
    "\n",
    "    # Calcular métricas finales para entrenamiento y prueba\n",
    "    y_pred_train = np.matmul(X_train, W)\n",
    "    y_pred_test = np.matmul(X_test, W)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    train_mape = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "\n",
    "    print(\"Métricas sobre los datos de entrenamiento:\")\n",
    "    print(f\"Mean Squared Error (MSE): {train_mse}\")\n",
    "    print(f\"R-squared: {train_r2}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {train_mae}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {train_mape}\")\n",
    "\n",
    "    print(\"Métricas sobre los datos de prueba:\")\n",
    "    print(f\"Mean Squared Error (MSE): {test_mse}\")\n",
    "    print(f\"R-squared: {test_r2}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {test_mae}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {test_mape}\")\n",
    "\n",
    "    # Graficar errores de entrenamiento y prueba\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_errors, label='Error de entrenamiento')\n",
    "    plt.plot(test_errors, label='Error de test')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Error cuadrático medio')\n",
    "    plt.legend()\n",
    "    plt.title('Error de entrenamiento y prueba vs iteraciones (GD)')\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "468ea90e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.361578Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test_scaled = scaler.fit_transform(y_test.values.reshape(-1,1))\n",
    "\n",
    "X_train_scaled1=scaler.fit_transform(X_train)\n",
    "X_test_scaled1=scaler.transform(X_test)\n",
    "\n",
    "y_train_scaled1 = scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test_scaled1 = scaler.fit_transform(y_test.values.reshape(-1,1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8b52e45",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.363328Z"
    }
   },
   "source": [
    "gradient_descent(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, lr=0.001, epochs=2000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69706e41",
   "metadata": {},
   "source": [
    "Con Gradiente Descendiente, el MSE de prueba coincide con el de la regresión lineal en la predicción. Requiere 2000 iteraciones para lograrlo, utilizando una tasa de aprendizaje de 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f924640e2433560",
   "metadata": {},
   "source": [
    "# Métodos de regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "id": "80700d4061ff9253",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.365263Z"
    }
   },
   "source": [
    "# Crear y entrenar el modelo Lasso\n",
    "lasso_model = Lasso(alpha=0.1)  # alpha es el parámetro de regularización\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_train = lasso_model.predict(X_train)\n",
    "y_pred_test = lasso_model.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test, \"Métricas sobre los datos de prueba:\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a34c6c2ede0a313f",
   "metadata": {},
   "source": [
    "## Lasso con grid_search con CV"
   ]
  },
  {
   "cell_type": "code",
   "id": "2fa0b8b57ead9fa5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.366792Z"
    }
   },
   "source": [
    "# Define los valores de los hiperparámetros que quieres explorar\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]  # Lista de valores para alpha\n",
    "}\n",
    "lasso_model = Lasso()\n",
    "grid_search = GridSearchCV(estimator=lasso_model, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error',  # Métrica de evaluación\n",
    "                           cv=5)  # Número de divisiones de validación cruzada\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Mejores hiperparámetros encontrados:{}\".format(grid_search.best_params_))\n",
    "y_pred_train_gs = grid_search.predict(X_train)\n",
    "y_pred_test_gs = grid_search.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train_gs, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test_gs, \"Métricas sobre los datos de prueba:\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f897c0f16e3b8099",
   "metadata": {},
   "source": [
    "# Regresión de Ridge"
   ]
  },
  {
   "cell_type": "code",
   "id": "842aa36fe521c58a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.368723Z"
    }
   },
   "source": [
    "ridge_model = Ridge(alpha=0.1)  # alpha es el parámetro de regularización\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_train = ridge_model.predict(X_train)\n",
    "y_pred_test = ridge_model.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test, \"Métricas sobre los datos de prueba:\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9df99d7a369e71a",
   "metadata": {},
   "source": [
    "## Ridge con grid_search"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3a4b9ce65d226f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.370514Z"
    }
   },
   "source": [
    "inicio = 0.01\n",
    "fin = 10.0\n",
    "paso = 0.01\n",
    "\n",
    "alphas = [inicio + i * paso for i in range(int((fin - inicio) / paso) + 1)]\n",
    "param_grid = {\n",
    "    'alpha': alphas\n",
    "}\n",
    "ridge_model = Ridge()\n",
    "grid_search = GridSearchCV(estimator=ridge_model, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error',  # Métrica de evaluación\n",
    "                           cv=5)  # Número de divisiones de validación cruzada\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Mejores hiperparámetros encontrados:{grid_search.best_params_}\")\n",
    "y_pred_train_gs = grid_search.predict(X_train)\n",
    "y_pred_test_gs = grid_search.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train_gs, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test_gs, \"Métricas sobre los datos de prueba:\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91186741d6a6bb2e",
   "metadata": {},
   "source": [
    "## Método de regularización Elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "id": "76bcb052d5902628",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.371907Z"
    }
   },
   "source": [
    "elastic_net_model = ElasticNet(alpha=0.1, l1_ratio=0.5)  # alpha es el parámetro de regularización, l1_ratio controla la proporción de L1 y L2\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "y_pred_train = elastic_net_model.predict(X_train)\n",
    "y_pred_test = elastic_net_model.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test, \"Métricas sobre los datos de prueba:\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "83d2fb33a35635fe",
   "metadata": {},
   "source": [
    "## Elasticnet con validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "id": "1888fd91fc4433cb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.373501Z"
    }
   },
   "source": [
    "alphas = [0.001, 0.1, 0.3, 0.5, 0.8, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "elastic_net_cv_model = ElasticNetCV(alphas=alphas, l1_ratio=l1_ratios)\n",
    "elastic_net_cv_model.fit(X_train, y_train)\n",
    "y_pred_train_cv = elastic_net_cv_model.predict(X_train)\n",
    "y_pred_test_cv = elastic_net_cv_model.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train_cv, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test_cv, \"Métricas sobre los datos de prueba:\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa38827ef3e2d7a9",
   "metadata": {},
   "source": [
    "## Elasticnet con random_search"
   ]
  },
  {
   "cell_type": "code",
   "id": "e68e8c185a8166ef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.375060Z"
    }
   },
   "source": [
    "param_distributions = {\n",
    "    'alpha': uniform(0.01, 10.0),  # Rango uniforme entre 0.1 y 10.0 para alpha\n",
    "    'l1_ratio': uniform(0, 1),     # Rango uniforme entre 0 y 1 para l1_ratio\n",
    "}\n",
    "elastic_net_model = ElasticNet()\n",
    "random_search = RandomizedSearchCV(estimator=elastic_net_model, \n",
    "                                   param_distributions=param_distributions, \n",
    "                                   n_iter=100,  # Número de iteraciones de búsqueda aleatoria\n",
    "                                   scoring='neg_mean_squared_error',  # Métrica de evaluación\n",
    "                                   cv=5,  # Número de divisiones de validación cruzada\n",
    "                                   random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f\"Mejores hiperparámetros encontrados:{random_search.best_params_}\")\n",
    "y_pred_train_rs = random_search.predict(X_train)\n",
    "y_pred_test_rs = random_search.predict(X_test)\n",
    "show_metrics_regresion(y_train, y_pred_train_rs, \"Métricas sobre los datos de entrenamiento:\")\n",
    "show_metrics_regresion(y_test, y_pred_test_rs, \"Métricas sobre los datos de prueba:\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "26ce520ca1c9c54d",
   "metadata": {},
   "source": [
    "### Regresión Lineal (Simple)\n",
    "No requiere optimización de hiperparámetros.\n",
    "La regresión lineal simple no tiene hiperparámetros que necesiten ajuste.\n",
    "### Ridge Regression (Regresión Ridge)\n",
    "Método de búsqueda sugerido: Grid Search\n",
    "Ridge Regression solo tiene un hiperparámetro principal (alpha), que controla la regularización. Dado que el espacio de búsqueda es unidimensional y generalmente pequeño, Grid Search es eficiente y suficientemente exhaustivo para encontrar el mejor valor de alpha.\n",
    "### Lasso Regression (Regresión Lasso)\n",
    "Método de búsqueda sugerido: Grid Search\n",
    "Similar a Ridge Regression, Lasso tiene un único hiperparámetro (alpha). Grid Search es adecuado porque permite una búsqueda exhaustiva en un espacio de búsqueda unidimensional.\n",
    "\n",
    "### Elastic Net\n",
    "Método de búsqueda sugerido: Random Search\n",
    "Elastic Net tiene dos hiperparámetros (alpha y l1_ratio). El espacio de búsqueda es bidimensional y potencialmente grande. Random Search es más eficiente en este caso porque puede explorar un mayor número de combinaciones de hiperparámetros en menos tiempo en comparación con Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3f825078f96f6",
   "metadata": {},
   "source": [
    "### Con respecto a las métricas, elegimos el r2 para comparar los distintos modelos\n",
    "### Necesitamos comparar los resultados obtenidos tanto en entrenamiento como en prueba para poder determinar si nuestro modelo esta ajustando correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15cee09ae0ec977",
   "metadata": {},
   "source": [
    "\n",
    "# Regresión Logística para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a00f49c08b167bd",
   "metadata": {},
   "source": [
    "### Definimos las variables para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "id": "f87581704bf8d9b6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.376648Z"
    }
   },
   "source": [
    "y_train_clasification =train['RainTomorrow']\n",
    "y_test_clasification = test['RainTomorrow']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14c8e7aa9146945f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.378153Z"
    }
   },
   "source": [
    "logistic_model1 = LogisticRegression(random_state=42)\n",
    "logistic_model1.fit(X_train, y_train_clasification)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_train = logistic_model1.predict(X_train)\n",
    "y_pred_test = logistic_model1.predict(X_test)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de entrenamiento\n",
    "ax1.text(0, 1, \"Classification Report para el conjunto de entrenamiento:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0.55, classification_report(y_train_clasification, y_pred_train), fontsize=10, family='monospace')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Añadir una pequeña separación vertical\n",
    "ax1.text(0, 0.5, \"-\" * 95, fontsize=10)\n",
    "\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de prueba\n",
    "ax1.text(0, 0.45, \"Classification Report para el conjunto de prueba:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0, classification_report(y_test_clasification, y_pred_test), fontsize=10, family='monospace')\n",
    "\n",
    "ax1.axis('off')\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_clasification, y_pred_test)\n",
    "show_metrics_extras(y_train_clasification, y_pred_train, title='Metricas extras En Entrenamiento')\n",
    "show_metrics_extras(y_test_clasification, y_pred_test, title='Metricas extras En Test')\n",
    "# Mostrar la matriz de confusión como un mapa de calor\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False, ax=ax2)\n",
    "ax2.set_xlabel('Predicción')\n",
    "ax2.set_ylabel('Valor Real')\n",
    "ax2.set_title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "36061b790c0b534b",
   "metadata": {},
   "source": [
    "## Regresión logística con penalización por clases"
   ]
  },
  {
   "cell_type": "code",
   "id": "72e628f69c797adf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.379694Z"
    }
   },
   "source": [
    "logistic_model2 = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logistic_model2.fit(X_train, y_train_clasification)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_train = logistic_model2.predict(X_train)\n",
    "y_pred_test = logistic_model2.predict(X_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de entrenamiento\n",
    "ax1.text(0, 1, \"Classification Report para el conjunto de entrenamiento:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0.55, classification_report(y_train_clasification, y_pred_train), fontsize=10, family='monospace')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Añadir una pequeña separación vertical\n",
    "ax1.text(0, 0.5, \"-\" * 95, fontsize=10)\n",
    "\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de prueba\n",
    "ax1.text(0, 0.45, \"Classification Report para el conjunto de prueba:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0, classification_report(y_test_clasification, y_pred_test), fontsize=10, family='monospace')\n",
    "\n",
    "ax1.axis('off')\n",
    "show_metrics_extras(y_test_clasification, y_pred_test, title='Metricas extras En Test')\n",
    "show_metrics_extras(y_train_clasification, y_pred_train, title='Metricas extras En Entrenamiento')\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_clasification, y_pred_test)\n",
    "\n",
    "# Mostrar la matriz de confusión como un mapa de calor\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False, ax=ax2)\n",
    "ax2.set_xlabel('Predicción')\n",
    "ax2.set_ylabel('Valor Real')\n",
    "ax2.set_title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bee63619ef307cf7",
   "metadata": {},
   "source": [
    "## Regresión logística con balanceo de clases SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "id": "1063615ca0dafdbb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.381470Z"
    }
   },
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_clasification)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14a4e5cd93ec69cc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.383012Z"
    }
   },
   "source": [
    "logistic_model3 = LogisticRegression(random_state=42)\n",
    "logistic_model3.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_train = logistic_model3.predict(X_train)\n",
    "y_pred_test = logistic_model3.predict(X_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de entrenamiento\n",
    "ax1.text(0, 1, \"Classification Report para el conjunto de entrenamiento:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0.55, classification_report(y_train_clasification, y_pred_train), fontsize=10, family='monospace')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Añadir una pequeña separación vertical\n",
    "ax1.text(0, 0.5, \"-\" * 95, fontsize=10)\n",
    "\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de prueba\n",
    "ax1.text(0, 0.45, \"Classification Report para el conjunto de prueba:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0, classification_report(y_test_clasification, y_pred_test), fontsize=10, family='monospace')\n",
    "\n",
    "ax1.axis('off')\n",
    "show_metrics_extras(y_train_clasification, y_pred_train, title='Metricas extras En Entrenamiento')\n",
    "show_metrics_extras(y_test_clasification, y_pred_test, title='Metricas extras En Test')\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_clasification, y_pred_test)\n",
    "# Mostrar la matriz de confusión como un mapa de calor\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False, ax=ax2)\n",
    "ax2.set_xlabel('Predicción')\n",
    "ax2.set_ylabel('Valor Real')\n",
    "ax2.set_title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "783f7890b36abebf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.384785Z"
    }
   },
   "source": [
    "# Obtener las probabilidades de predicción de la clase positiva para entrenamiento y prueba para cada modelo\n",
    "y_pred_proba_train1 = logistic_model1.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test1 = logistic_model1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_proba_train2 = logistic_model2.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test2 = logistic_model2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_proba_train3 = logistic_model3.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test3 = logistic_model3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcula la curva ROC y el área bajo la curva para el modelo 1\n",
    "fpr_train1, tpr_train1, _ = roc_curve(y_train_clasification, y_pred_proba_train1)\n",
    "fpr_test1, tpr_test1, umbrales_test1 = roc_curve(y_test_clasification, y_pred_proba_test1)\n",
    "auc_train1 = roc_auc_score(y_train_clasification, y_pred_proba_train1)\n",
    "auc_test1 = roc_auc_score(y_test_clasification, y_pred_proba_test1)\n",
    "\n",
    "# Encuentra el umbral óptimo para el modelo 1\n",
    "indice_umbral_optimo1 = np.argmax(tpr_test1 - fpr_test1)\n",
    "umbral_optimo_modelo1 = umbrales_test1[indice_umbral_optimo1]\n",
    "\n",
    "print(\"Umbral óptimo para el modelo 1:\", umbral_optimo_modelo1)\n",
    "\n",
    "# Calcula la curva ROC y el área bajo la curva para el modelo 2\n",
    "fpr_train2, tpr_train2, _ = roc_curve(y_train_clasification, y_pred_proba_train2)\n",
    "fpr_test2, tpr_test2, umbrales_test2 = roc_curve(y_test_clasification, y_pred_proba_test2)\n",
    "auc_train2 = roc_auc_score(y_train_clasification, y_pred_proba_train2)\n",
    "auc_test2 = roc_auc_score(y_test_clasification, y_pred_proba_test2)\n",
    "\n",
    "# Encuentra el umbral óptimo para el modelo 2\n",
    "indice_umbral_optimo2 = np.argmax(tpr_test2 - fpr_test2)\n",
    "umbral_optimo_modelo2 = umbrales_test2[indice_umbral_optimo2]\n",
    "\n",
    "print(\"Umbral óptimo para el modelo 2:\", umbral_optimo_modelo2)\n",
    "\n",
    "# Calcula la curva ROC y el área bajo la curva para el modelo 3\n",
    "fpr_train3, tpr_train3, _ = roc_curve(y_train_clasification, y_pred_proba_train3)\n",
    "fpr_test3, tpr_test3, umbrales_test3 = roc_curve(y_test_clasification, y_pred_proba_test3)\n",
    "auc_train3 = roc_auc_score(y_train_clasification, y_pred_proba_train3)\n",
    "auc_test3 = roc_auc_score(y_test_clasification, y_pred_proba_test3)\n",
    "\n",
    "# Encuentra el umbral óptimo para el modelo 3\n",
    "indice_umbral_optimo3 = np.argmax(tpr_test3 - fpr_test3)\n",
    "umbral_optimo_modelo3 = umbrales_test3[indice_umbral_optimo3]\n",
    "\n",
    "print(\"Umbral óptimo para el modelo 3:\", umbral_optimo_modelo3)\n",
    "\n",
    "\n",
    "# Trazar las curvas ROC para entrenamiento y prueba para cada modelo en una sola fila\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Modelo 1\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr_train1, tpr_train1, color='blue', lw=2, label='Entrenamiento (AUC = %0.2f)' % auc_train1)\n",
    "plt.plot(fpr_test1, tpr_test1, color='red', lw=2, label='Prueba (AUC = %0.2f)' % auc_test1)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC - Regresión Logística')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(0.5, 0.3, f'Umbral óptimo = {umbral_optimo_modelo1:.2f}', fontsize=10, ha='center')\n",
    "\n",
    "# Modelo 2\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(fpr_train2, tpr_train2, color='blue', lw=2, label='Entrenamiento (AUC = %0.2f)' % auc_train2)\n",
    "plt.plot(fpr_test2, tpr_test2, color='red', lw=2, label='Prueba (AUC = %0.2f)' % auc_test2)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC - Regresión Logística con penalización por clases')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(0.5, 0.3, f'Umbral óptimo = {umbral_optimo_modelo2:.2f}', fontsize=10, ha='center')\n",
    "\n",
    "# Modelo 3\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(fpr_train3, tpr_train3, color='blue', lw=2, label='Entrenamiento (AUC = %0.2f)' % auc_train3)\n",
    "plt.plot(fpr_test3, tpr_test3, color='red', lw=2, label='Prueba (AUC = %0.2f)' % auc_test3)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC - Regresión Logística con balanceo de clases SMOTE')\n",
    "plt.legend(loc='lower right')\n",
    "plt.text(0.5, 0.3, f'Umbral óptimo = {umbral_optimo_modelo3:.2f}', fontsize=10, ha='center')\n",
    "\n",
    "# Ajustar espaciado entre subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "809d67e90555e70a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.386532Z"
    }
   },
   "source": [
    "logistic_model_SMOTE_HYPER = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logistic_model_SMOTE_HYPER.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Calcular las probabilidades de predicción para la clase positiva\n",
    "y_pred_proba_train = logistic_model_SMOTE_HYPER.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = logistic_model_SMOTE_HYPER.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular las curvas ROC y AUC\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train_clasification, y_pred_proba_train)\n",
    "fpr_test, tpr_test, umbrales_test = roc_curve(y_test_clasification, y_pred_proba_test)\n",
    "auc_train = roc_auc_score(y_train_clasification, y_pred_proba_train)\n",
    "auc_test = roc_auc_score(y_test_clasification, y_pred_proba_test)\n",
    "\n",
    "# Encontrar el umbral óptimo\n",
    "umbral_optimo = umbrales_test[np.argmax(tpr_test - fpr_test)]\n",
    "\n",
    "# Crear una nueva figura y subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Trazar la curva ROC en el primer subplot\n",
    "ax1.plot(fpr_train, tpr_train, color='blue', lw=2, label='Entrenamiento (AUC = %0.2f)' % auc_train)\n",
    "ax1.plot(fpr_test, tpr_test, color='red', lw=2, label='Prueba (AUC = %0.2f)' % auc_test)\n",
    "ax1.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "ax1.scatter(fpr_test[np.argmax(tpr_test - fpr_test)], tpr_test[np.argmax(tpr_test - fpr_test)], marker='o', color='black', label=f'Umbral óptimo = {umbral_optimo:.2f}')\n",
    "ax1.axvline(x=fpr_test[np.argmax(tpr_test - fpr_test)], color='black', linestyle='--', ymax=tpr_test[np.argmax(tpr_test - fpr_test)], linewidth=0.5)\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('Tasa de falsos positivos')\n",
    "ax1.set_ylabel('Tasa de verdaderos positivos')\n",
    "ax1.set_title('Curva ROC')\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# Mostrar la matriz de confusión como un mapa de calor en el segundo subplot\n",
    "conf_matrix = confusion_matrix(y_test_clasification, y_pred_test)\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False, ax=ax2)\n",
    "ax2.set_xlabel('Predicción')\n",
    "ax2.set_ylabel('Valor Real')\n",
    "ax2.set_title('Matriz de Confusión')\n",
    "\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de entrenamiento\n",
    "ax3.text(0, 1, \"Classification Report para el conjunto de entrenamiento:\", fontsize=12, weight='bold')\n",
    "ax3.text(0, 0.55, classification_report(y_train_clasification, y_pred_train), fontsize=10, family='monospace')\n",
    "ax3.axis('off')\n",
    "\n",
    "# Añadir una pequeña separación vertical\n",
    "ax3.text(0, 0.5, \"-\" * 95, fontsize=10)\n",
    "\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de prueba\n",
    "ax3.text(0, 0.45, \"Classification Report para el conjunto de prueba:\", fontsize=12, weight='bold')\n",
    "ax3.text(0, 0, classification_report(y_test_clasification, y_pred_test), fontsize=10, family='monospace')\n",
    "ax3.axis('off')\n",
    "\n",
    "# Mostrar las métricas extras\n",
    "show_metrics_extras(y_train_clasification, y_pred_train, title='Metricas extras En Entrenamiento')\n",
    "show_metrics_extras(y_test_clasification, y_pred_test, title='Metricas extras En Test')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5dae54198cbd9076",
   "metadata": {},
   "source": [
    "## Regresion logistica con Hiper Parametros "
   ]
  },
  {
   "cell_type": "code",
   "id": "afb57b37f56a5a27",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.388144Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def print_dataframe(filtered_cv_results):\n",
    "    ### print de los resultados de cross validation\n",
    "    for mean_precision, std_precision, mean_recall, std_recall, params in zip(\n",
    "        filtered_cv_results[\"mean_test_precision\"],\n",
    "        filtered_cv_results[\"std_test_precision\"],\n",
    "        filtered_cv_results[\"mean_test_recall\"],\n",
    "        filtered_cv_results[\"std_test_recall\"],\n",
    "        filtered_cv_results[\"params\"],\n",
    "    ):\n",
    "        print(\n",
    "            f\"precision: {mean_precision:0.3f} (±{std_precision:0.03f}),\"\n",
    "            f\" recall: {mean_recall:0.3f} (±{std_recall:0.03f}),\"\n",
    "            f\" for {params}\"\n",
    "        )\n",
    "    print()\n",
    "\n",
    "\n",
    "def refit_strategy(cv_results):\n",
    "    \"\"\"Define the strategy to select the best estimator.\n",
    "\n",
    "    The strategy defined here is to filter-out all results below a precision threshold\n",
    "    of 0.7, rank the remaining by recall and keep all models with one standard\n",
    "    deviation of the best by recall. Once these models are selected, we can select the\n",
    "    fastest model to predict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy (masked) ndarrays\n",
    "        CV results as returned by the `GridSearchCV`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_index : int\n",
    "        The index of the best estimator as it appears in `cv_results`.\n",
    "    \"\"\"\n",
    "    # print the info about the grid-search for the different scores\n",
    "    precision_threshold = 0.7\n",
    "\n",
    "    cv_results_ = pd.DataFrame(cv_results)\n",
    "    print(\"All grid-search results:\")\n",
    "    print_dataframe(cv_results_)\n",
    "\n",
    "    # Filter-out all results below the threshold\n",
    "    high_precision_cv_results = cv_results_[\n",
    "        cv_results_[\"mean_test_precision\"] > precision_threshold\n",
    "    ]\n",
    "\n",
    "    print(f\"Models with a precision higher than {precision_threshold}:\")\n",
    "    print_dataframe(high_precision_cv_results)\n",
    "\n",
    "    high_precision_cv_results = high_precision_cv_results[\n",
    "        [\n",
    "            \"mean_score_time\",\n",
    "            \"mean_test_recall\",\n",
    "            \"std_test_recall\",\n",
    "            \"mean_test_precision\",\n",
    "            \"std_test_precision\",\n",
    "            \"rank_test_recall\",\n",
    "            \"rank_test_precision\",\n",
    "            \"params\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Select the most performant models in terms of recall\n",
    "    # (within 1 sigma from the best)\n",
    "    best_recall_std = high_precision_cv_results[\"mean_test_recall\"].std()\n",
    "    best_recall = high_precision_cv_results[\"mean_test_recall\"].max()\n",
    "    best_recall_threshold = best_recall - best_recall_std\n",
    "\n",
    "    high_recall_cv_results = high_precision_cv_results[\n",
    "        high_precision_cv_results[\"mean_test_recall\"] > best_recall_threshold\n",
    "    ]\n",
    "    print(\n",
    "        \"Out of the previously selected high precision models, we keep all the\\n\"\n",
    "        \"the models within one standard deviation of the highest recall model:\"\n",
    "    )\n",
    "    print_dataframe(high_recall_cv_results)\n",
    "\n",
    "    # From the best candidates, select the fastest model to predict\n",
    "    fastest_top_recall_high_precision_index = high_recall_cv_results[\n",
    "        \"mean_score_time\"\n",
    "    ].idxmin()\n",
    "\n",
    "    print(\n",
    "        \"\\nThe selected final model is the fastest to predict out of the previously\\n\"\n",
    "        \"selected subset of best models based on precision and recall.\\n\"\n",
    "        \"Its scoring time is:\\n\\n\"\n",
    "        f\"{high_recall_cv_results.loc[fastest_top_recall_high_precision_index]}\"\n",
    "    )\n",
    "\n",
    "    return fastest_top_recall_high_precision_index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a59d9001f5ab65eb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.390104Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definir los parámetros del modelo a tunear\n",
    "tuned_parameters = [\n",
    "    {\"class_weight\": [None, 'balanced'], \"C\": [0.1, 1, 10, 100], \"solver\": ['newton-cg'], \"max_iter\": [200, 1000]}\n",
    "]\n",
    "\n",
    "# Definir las métricas de evaluación\n",
    "scores = [\"precision\", \"recall\"]\n",
    "\n",
    "# Escalar los datos de entrenamiento y prueba\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir la estrategia de refit (utilizar 'recall' como métrica principal para refit)\n",
    "refit_strategy = \"recall\"\n",
    "\n",
    "# Configurar y ajustar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid=tuned_parameters,\n",
    "    scoring={'precision': 'precision', 'recall': 'recall'},\n",
    "    refit=refit_strategy,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "grid_search.fit(X_train_scaled, y_train_clasification)\n",
    "\n",
    "# Mejor combinación de hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "\n",
    "# Mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones y métricas con el mejor modelo\n",
    "y_pred_train = best_model.predict(X_train_scaled)\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Reporte de clasificación en datos de entrenamiento:\")\n",
    "print(classification_report(y_train_clasification, y_pred_train))\n",
    "\n",
    "print(\"Reporte de clasificación en datos de prueba:\")\n",
    "print(classification_report(y_test_clasification, y_pred_test))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f2623e4b64c3e3de",
   "metadata": {},
   "source": [
    "###  En este caso, elegimos recall, ya que mide la proporción de verdaderos positivos entre todas las instancias que realmente son positivas. Al centrarnos en el recall, estamos evaluando la capacidad del modelo para capturar correctamente los casos en que realmente llueve.  Una alta tasa de recall indica que el modelo es efectivo para identificar los casos de lluvia, lo que es crucial si el costo de los falsos negativos es alto y quieres minimizarlos. \n",
    "\n",
    "##### Falsos Negativos (FN)\n",
    "\n",
    "Un falso negativo en este contexto ocurre cuando el modelo predice que no va a llover mañana, pero en realidad sí llueve.\n",
    "\n",
    "##### Falsos Positivos (FP)\n",
    "\n",
    "Un falso positivo en este contexto ocurre cuando el modelo predice que va a llover mañana, pero en realidad no llueve.\n",
    "\n",
    "En el contexto de nuestro problema, la clasificación incorrecta puede resultar en inconvenientes menores, como salir sin paraguas o llevar un paraguas innecesariamente. Sin embargo, en contextos donde intervienen factores más serios, como la salud de una persona, los impactos de los falsos negativos y falsos positivos pueden ser mucho más graves.\n",
    "\n",
    "Por ejemplo, en el caso de una enfermedad, un falso negativo podría significar que una enfermedad grave no se detecta a tiempo, poniendo en peligro la vida del paciente. Un falso positivo podría llevar a tratamientos innecesarios, ansiedad y costos adicionales. Por lo tanto, en tales contextos, nuestro objetivo sería minimizar estos errores tanto como sea posible. Idealmente, buscariamos reducir a cero los valores de falsos negativos, ya que no detectar una condición crítica puede tener consecuencias severas. En caso de no poder eliminar completamente estos errores, trataríamos de reducirlos al mínimo número posible para garantizar la seguridad y el bienestar de las personas.\n",
    "\n",
    "##### umbrales\n",
    "Tras analizar los umbrales óptimos obtenidos para los tres modelos, observamos diferencias significativas que reflejan las características particulares de cada enfoque de modelado.\n",
    "\n",
    "Para el Modelo 1, que se construyó sobre datos desbalanceados, el umbral óptimo identificado es de 0.23. Este valor tan bajo sugiere una tendencia a clasificar más instancias como positivas, lo cual es comprensible dado el desbalance en los datos. Aquí, un umbral cercano a 0.5 podría no ser el más adecuado, dada la distribución de clases.\n",
    "\n",
    "En contraste, el Modelo 2 incorporó una estrategia de ponderación de clases para abordar el desbalance. Con un umbral óptimo de 0.49, este modelo muestra una mayor sensibilidad hacia los verdaderos positivos, lo que sugiere una mejor capacidad para detectar casos positivos en un conjunto de datos más equilibrado. Aunque el umbral se acerca a 0.5, indicando una tendencia a la neutralidad, su ligero descenso sugiere una adaptación a la corrección de clases desbalanceadas.\n",
    "\n",
    "Por último, el Modelo 3 se construyó sobre datos balanceados mediante la técnica SMOTE. Su umbral óptimo, alrededor de 0.47, refleja una ponderación similar entre precisión y sensibilidad. Aunque no es significativamente diferente de 0.5, esta ligera variación indica una consideración hacia la corrección del desbalance y la preservación de la sensibilidad del modelo.\n",
    "\n",
    "##### Fitting\n",
    "El rendimiento de nuestro modelo, con un recall del 75% en ambas clases y un área bajo la curva (AUC) de 0.80, sugiere un ajuste notablemente sólido a los datos. Un recall del 75% indica que nuestro modelo puede identificar correctamente el 75% de todas las instancias positivas, lo que refleja su capacidad para capturar de manera efectiva los casos relevantes.\n",
    "\n",
    "El AUC, por otro lado, es una medida de la capacidad del modelo para distinguir entre clases. Con un valor de 0.80, nuestro modelo muestra una buena capacidad para discriminar entre las clases positiva y negativa, lo que indica que es capaz de clasificar adecuadamente las instancias en función de su clase verdadera.\n",
    "\n",
    "La combinación de un recall equilibrado en ambas clases y un AUC sólido sugiere que nuestro modelo está logrando un buen equilibrio entre la sensibilidad y la especificidad, lo que significa que no solo puede identificar positivos con precisión, sino que también puede distinguir con éxito entre los positivos y los negativos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee5c27",
   "metadata": {},
   "source": [
    "## Explicabilidad del modelo con SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c59b17",
   "metadata": {},
   "source": [
    "### INTERPRETABILIDAD LOCAL CLASIFICACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "id": "39d51201",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.392005Z"
    }
   },
   "source": [
    "explainer = shap.LinearExplainer(logistic_model1, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "index=0\n",
    "logistic_model1.predict_proba(X_test)[index]\n",
    "logistic_model1.predict(X_test)[index]\n",
    "shap_values[index]\n",
    "explanation = shap.Explanation(values=shap_values[index], base_values=explainer.expected_value, feature_names=X_train.columns)\n",
    "shap.plots.waterfall(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b5ed5b4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.393536Z"
    }
   },
   "source": [
    "shap.plots.waterfall(explanation, max_display=4)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9aa412a8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.394957Z"
    }
   },
   "source": [
    "shap.plots.bar(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0db00707",
   "metadata": {},
   "source": [
    "### INTEPRETABILIDAD GLOBAL CLASIFICACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "id": "08bfc504",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.396552Z"
    }
   },
   "source": [
    "explanation = shap.Explanation(values=shap_values, base_values=explainer.expected_value, feature_names=X_test.columns, data=X_test)\n",
    "shap.plots.bar(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6253f3cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T23:17:15.498104Z",
     "start_time": "2024-06-09T23:17:15.398064Z"
    }
   },
   "source": [
    "shap.plots.beeswarm(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ab92802d",
   "metadata": {},
   "source": [
    "### INTEPRETABILIDAD LOCAL REGRESIÓN"
   ]
  },
  {
   "cell_type": "code",
   "id": "7fb27aee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.399640Z"
    }
   },
   "source": [
    "explainer = shap.LinearExplainer(model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "index=0\n",
    "model.predict(X_test)[index]\n",
    "shap_values[index]\n",
    "explanation = shap.Explanation(values=shap_values[index], base_values=explainer.expected_value, feature_names=X_train.columns)\n",
    "shap.plots.waterfall(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca986609",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.401446Z"
    }
   },
   "source": [
    "shap.plots.waterfall(explanation, max_display=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9739bd9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.403206Z"
    }
   },
   "source": [
    "shap.plots.bar(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c00fb3e3",
   "metadata": {},
   "source": [
    "### INTEPRETABILIDAD GLOBAL REGRESIÓN"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b26a9e7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.404883Z"
    }
   },
   "source": [
    "explanation = shap.Explanation(values=shap_values, base_values=explainer.expected_value, feature_names=X_test.columns, data=X_test)\n",
    "shap.plots.bar(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1bd7e5f9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.406371Z"
    }
   },
   "source": [
    "shap.plots.beeswarm(explanation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39ddcdbd",
   "metadata": {},
   "source": [
    "El gráfico de valores SHAP revela la importancia y el impacto de cada característica en las predicciones del modelo. \n",
    "\n",
    "Características con valores SHAP más altos, como rainfall, tienen una influencia más fuerte en las predicciones, mientras que aquellos cerca de cero tienen un efecto mínimo, como las que aparecen como la suma de otras 3 features.\n",
    "\n",
    "Cada punto representa un valor SHAP de una característica para una observación específica. \n",
    "\n",
    "La dispersión de los puntos a lo largo del eje X indica la magnitud y la dirección del impacto de la característica en la predicción. \n",
    "\n",
    "Características más importantes están ubicadas más arriba en el gráfico\n",
    "\n",
    "Las variables más importantes en el modelo de clasificación son Sunshine, MaxTemp y WindGustSpeed\n",
    "\n",
    "las variables menos importantes en el modelo de clasificación son Evaporation y CloudVariation\n",
    "\n",
    "Las variables más importantes en el modelo de regresión son Sunshine, PressureVariation y HumidityVariation\n",
    "\n",
    "las variables menos importantes en el modelo de regresión son Evaporation y TempVariation\n",
    "\n",
    "Podemos observar que no coinciden en ambos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1aeb5df1e99853",
   "metadata": {},
   "source": [
    "## Modelo Base para Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "id": "da1f443f8d4947c1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.407870Z"
    }
   },
   "source": [
    "# Crear el clasificador ingenuo que predice la clase mayoritaria\n",
    "naive_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "naive_classifier.fit(X_train, y_train_clasification)\n",
    "\n",
    "# Hacer predicciones sobre los datos de entrenamiento y prueba\n",
    "y_pred_train = naive_classifier.predict(X_train)\n",
    "y_pred_test = naive_classifier.predict(X_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de entrenamiento\n",
    "ax1.text(0, 1, \"Classification Report para el conjunto de entrenamiento:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0.55, classification_report(y_train_clasification, y_pred_train), fontsize=10, family='monospace')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Añadir una pequeña separación vertical\n",
    "ax1.text(0, 0.5, \"-\" * 95, fontsize=10)\n",
    "\n",
    "# Mostrar el cuadro de texto (classification report) para el conjunto de prueba\n",
    "ax1.text(0, 0.45, \"Classification Report para el conjunto de prueba:\", fontsize=12, weight='bold')\n",
    "ax1.text(0, 0, classification_report(y_test_clasification, y_pred_test), fontsize=10, family='monospace')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_clasification, y_pred_test)\n",
    "# Mostrar la matriz de confusión como un mapa de calor\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False, ax=ax2)\n",
    "ax2.set_xlabel('Predicción')\n",
    "ax2.set_ylabel('Valor Real')\n",
    "ax2.set_title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "28ca437b1565060f",
   "metadata": {},
   "source": [
    "## curva ROC de modelo base"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3f61d2b5e6cb3a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.409796Z"
    }
   },
   "source": [
    "# Obtener las probabilidades de predicción de la clase positiva (la clase mayoritaria)\n",
    "y_pred_proba_train = np.full_like(y_train_clasification, fill_value=1)  # Clase mayoritaria\n",
    "y_pred_proba_test = np.full_like(y_test_clasification, fill_value=1)  # Clase mayoritaria\n",
    "\n",
    "# Calcular la curva ROC para los datos de entrenamiento y prueba\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train_clasification, y_pred_proba_train)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test_clasification, y_pred_proba_test)\n",
    "\n",
    "# Calcular el área bajo la curva ROC (AUC) para los datos de entrenamiento y prueba\n",
    "auc_train = roc_auc_score(y_train_clasification, y_pred_proba_train)\n",
    "auc_test = roc_auc_score(y_test_clasification, y_pred_proba_test)\n",
    "\n",
    "# Crear la figura con dos subplots uno al lado del otro\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Trazar la curva ROC para los datos de entrenamiento\n",
    "ax1.plot(fpr_train, tpr_train, color='blue', lw=2, label='Train ROC curve (AUC = %0.2f)' % auc_train)\n",
    "ax1.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('Tasa de falsos positivos')\n",
    "ax1.set_ylabel('Tasa de verdaderos positivos')\n",
    "ax1.set_title('Curva ROC para datos de entrenamiento')\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# Trazar la curva ROC para los datos de prueba\n",
    "ax2.plot(fpr_test, tpr_test, color='red', lw=2, label='Test ROC curve (AUC = %0.2f)' % auc_test)\n",
    "ax2.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "ax2.set_xlim([0.0, 1.0])\n",
    "ax2.set_ylim([0.0, 1.05])\n",
    "ax2.set_xlabel('Tasa de falsos positivos')\n",
    "ax2.set_ylabel('Tasa de verdaderos positivos')\n",
    "ax2.set_title('Curva ROC para datos de prueba')\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60b02b41",
   "metadata": {},
   "source": [
    "Podemos observar que el modelo base no tiene capacidad discriminativa mejor que una predicción aleatoria, no puede distinguir entre las clases positivas y negativas de manera significativa, lo que limita su utilidad para clasificar correctamente los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9ea938a6082da",
   "metadata": {},
   "source": [
    "## Modelo Base para Regresión"
   ]
  },
  {
   "cell_type": "code",
   "id": "a7d7945def41f2e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.411509Z"
    }
   },
   "source": [
    "# Crear un DummyRegressor que predice la media de la variable objetivo\n",
    "dummy_regressor = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entrenar el modelo de regresión base con los datos de entrenamiento\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones con el modelo de regresión base en los datos de entrenamiento y prueba\n",
    "y_pred_train_base = dummy_regressor.predict(X_train)\n",
    "y_pred_test_base = dummy_regressor.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) del modelo de regresión base para el conjunto de entrenamiento y prueba\n",
    "mse_train_base = mean_squared_error(y_train, y_pred_train_base)\n",
    "mse_test_base = mean_squared_error(y_test, y_pred_test_base)\n",
    "\n",
    "# Calcular el Error Absoluto Medio (MAE) para el conjunto de entrenamiento y prueba\n",
    "mae_train_base = mean_absolute_error(y_train, y_pred_train_base)\n",
    "mae_test_base = mean_absolute_error(y_test, y_pred_test_base)\n",
    "\n",
    "# Calcular el Error Porcentual Absoluto Medio (MAPE) para el conjunto de prueba\n",
    "mape_test_base = np.mean(np.abs((y_test - y_pred_test_base) / y_test)) * 100\n",
    "\n",
    "# Calcular el coeficiente de determinación (R-cuadrado) para el conjunto de prueba\n",
    "r2_test_base = r2_score(y_test, y_pred_test_base)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Métricas para el modelo de regresión base:\")\n",
    "print(\"Error cuadrático medio (MSE) (Train):\", mse_train_base)\n",
    "print(\"Error cuadrático medio (MSE) (Test):\", mse_test_base)\n",
    "print(\"Mean Absolute Error (MAE) (Train):\", mae_train_base)\n",
    "print(\"Mean Absolute Error (MAE) (Test):\", mae_test_base)\n",
    "print(\"Mean Absolute Percentage Error (MAPE) (Test):\", mape_test_base)\n",
    "print(\"R-squared (Test):\", r2_test_base)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5e2fcad1",
   "metadata": {},
   "source": [
    "Podemos observar que la estrategia de implementar un modelo base de regresión tiene métricas inferiores a la regresión lineal simple y esto nos sirve como indicio para determinar que este modelo no se ajusta bien a nuestro problema, debido a esto decidimos que para los problemas de regresión vamos a optar por el método de la regresión lineal múltiple. Esta elección es parcial ya que aún no implementamos la solución con redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b5dec5ebb008a",
   "metadata": {},
   "source": [
    "# Red neuronal para Regresion"
   ]
  },
  {
   "cell_type": "code",
   "id": "16907cf6e855d601",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.413247Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(12,), activation='relu'))\n",
    "model.add(Dense(1, activation='linear')) \n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "show_metrics_regresion(y_train, y_pred_train,\"Métricas del conjunto de entrenamiento:\", False)\n",
    "show_metrics_regresion(y_test, y_pred_test,\"Métricas del conjunto de Prueba:\", False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9069ba9aee0dfa42",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "id": "8cb731837c79450b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.415314Z"
    }
   },
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "def objective(trial):\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 20)\n",
    "    hidden_layer_size = trial.suggest_int('hidden_layer_size', 16, 400)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'sigmoid', 'tanh'])\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_size, input_shape=(12,), activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(Dense(hidden_layer_size, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    \n",
    "    return mse_train\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = Sequential()\n",
    "best_model.add(Dense(best_params['hidden_layer_size'], input_shape=(12,), activation=best_params['activation']))\n",
    "best_model.add(Dropout(best_params['dropout_rate']))\n",
    "for _ in range(best_params['num_hidden_layers']):\n",
    "    best_model.add(Dense(best_params['hidden_layer_size'], activation=best_params['activation']))\n",
    "    best_model.add(Dropout(best_params['dropout_rate']))\n",
    "best_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "if best_params['optimizer'] == 'adam':\n",
    "    optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'rmsprop':\n",
    "    optimizer = RMSprop(learning_rate=best_params['learning_rate'])\n",
    "else:\n",
    "    optimizer = SGD(learning_rate=best_params['learning_rate'])\n",
    "\n",
    "best_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "best_model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "print(\"Mejores Hiperparámetros:\", best_params)\n",
    "show_metrics_regresion(y_test, y_pred_test, \"Conjunto de Prueba:\", nr_neuronal=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "95984b34",
   "metadata": {},
   "source": [
    "### Función de pérdida para el modelo de regresión"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c9adfcd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.416903Z"
    }
   },
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir el modelo con los mejores hiperparámetros\n",
    "model = Sequential()\n",
    "model.add(Dense(61, input_shape=(12,), activation='relu'))  # Capa oculta con 61 neuronas\n",
    "model.add(Dense(61, activation='relu'))  # Segunda capa oculta con 61 neuronas\n",
    "model.add(Dense(1, activation='linear'))  # Capa de salida\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Obtener la pérdida durante el entrenamiento\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Graficar la pérdida durante el entrenamiento\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "52090374f3fefa82",
   "metadata": {},
   "source": [
    "# Red neuronal para Clasificacion\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "aaea2b188bfdf9c5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.418897Z"
    }
   },
   "source": [
    "# Construir el modelo de red neuronal\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Capa de salida con activación sigmoide para clasificación binaria\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train_clasification, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train_clasification, verbose=0)\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", train_accuracy)\n",
    "print(\"Pérdida en el conjunto de entrenamiento:\", train_loss)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "print(\"Pérdida en el conjunto de prueba:\", test_loss)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "81c62550b9c0b0d1",
   "metadata": {},
   "source": [
    "## Optimizacion de hiper-parametros"
   ]
  },
  {
   "cell_type": "code",
   "id": "e651b51a4b8018e3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.420828Z"
    }
   },
   "source": [
    "best_accuracy = 0.0  # Seguimiento de la mejor precisión encontrada\n",
    "def objective(trial):\n",
    "    global best_accuracy  # Para acceder a la variable global\n",
    "\n",
    "    # Definir los hiperparámetros a optimizar\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 3)\n",
    "    hidden_layer_size = trial.suggest_int('hidden_layer_size', 16, 64)\n",
    "\n",
    "    # Construir el modelo de red neuronal\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_size, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(Dense(hidden_layer_size, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Capa de salida con activación sigmoide para clasificación binaria\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train_clasification, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    _, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Si es el mejor modelo hasta ahora, actualizar la mejor precisión encontrada\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    return test_accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Construir el mejor modelo con los mejores hiperparámetros\n",
    "best_model = Sequential()\n",
    "best_model.add(Dense(best_params['hidden_layer_size'], input_shape=(X_train.shape[1],), activation='relu'))\n",
    "for _ in range(best_params['num_hidden_layers']):\n",
    "    best_model.add(Dense(best_params['hidden_layer_size'], activation='relu'))\n",
    "best_model.add(Dense(1, activation='sigmoid'))  # Capa de salida con activación sigmoide para clasificación binaria\n",
    "\n",
    "best_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "best_model.fit(X_train, y_train_clasification, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de entrenamiento y de prueba\n",
    "train_loss, train_accuracy = best_model.evaluate(X_train, y_train_clasification, verbose=0)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(\"\\nMétricas del mejor modelo:\")\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", train_accuracy)\n",
    "print(\"Pérdida en el conjunto de entrenamiento:\", train_loss)\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "print(\"Pérdida en el conjunto de prueba:\", test_loss)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a3cbebb93fceb382",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.422328Z"
    }
   },
   "source": [
    "# Código utilizado para obtener los mejores hiperparámetros (lo dejamos comentado porque demora mucho tiempo)\n",
    "\"\"\"\n",
    "import optuna\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el conjunto de datos de entrenamiento en entrenamiento y validación\n",
    "X_train, X_valid, y_train_clasification, y_valid = train_test_split(X_train, y_train_clasification, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Definir el espacio de búsqueda de los hiperparámetros\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(32, 16), (64, 32), (128, 64), (100,), (50, 25, 12)])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic', 'identity'])\n",
    "    solver = trial.suggest_categorical('solver', ['adam', 'sgd', 'lbfgs'])\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-4, 1e-1)\n",
    "    learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
    "   \n",
    "    # Crear el modelo MLPClassifier con los hiperparámetros sugeridos\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                          activation=activation,\n",
    "                          solver=solver,\n",
    "                          alpha=alpha,\n",
    "                          learning_rate='constant',\n",
    "                          learning_rate_init=learning_rate_init,\n",
    "                          max_iter=200)\n",
    "   \n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train_clasification)\n",
    "   \n",
    "    # Evaluar el modelo en el conjunto de validación\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "   \n",
    "    return accuracy\n",
    "\n",
    "# Crear un estudio y optimizar\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params = study.best_params\n",
    "print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "best_model = MLPClassifier(**best_params, max_iter=200)\n",
    "best_model.fit(X_train, y_train_clasification)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train_clasification, y_train_pred)\n",
    "train_loss = log_loss(y_train_clasification, best_model.predict_proba(X_train))\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", train_accuracy)\n",
    "print(\"Pérdida en el conjunto de entrenamiento:\", train_loss)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test_clasification, y_test_pred)\n",
    "test_loss = log_loss(y_test_clasification, best_model.predict_proba(X_test))\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "print(\"Pérdida en el conjunto de prueba:\", test_loss)\n",
    "\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91bf9d29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.424086Z"
    }
   },
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "best_params = {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.005958432842192192, 'learning_rate_init': 0.0001422171191037891}\n",
    "# Entrenar el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "best_model = MLPClassifier(**best_params, max_iter=200)\n",
    "best_model.fit(X_train, y_train_clasification)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train_clasification, y_train_pred)\n",
    "train_loss = log_loss(y_train_clasification, best_model.predict_proba(X_train))\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", train_accuracy)\n",
    "print(\"Pérdida en el conjunto de entrenamiento:\", train_loss)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test_clasification, y_test_pred)\n",
    "test_loss = log_loss(y_test_clasification, best_model.predict_proba(X_test))\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "print(\"Pérdida en el conjunto de prueba:\", test_loss)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, recall_score\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train_clasification, y_train_pred)\n",
    "train_loss = log_loss(y_train_clasification, best_model.predict_proba(X_train))\n",
    "train_recall = recall_score(y_train_clasification, y_train_pred, average='weighted')\n",
    "print(\"Precisión en el conjunto de entrenamiento:\", train_accuracy)\n",
    "print(\"Pérdida en el conjunto de entrenamiento:\", train_loss)\n",
    "print(\"Recall en el conjunto de entrenamiento:\", train_recall)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test_clasification, y_test_pred)\n",
    "test_loss = log_loss(y_test_clasification, best_model.predict_proba(X_test))\n",
    "test_recall = recall_score(y_test_clasification, y_test_pred, average='weighted')\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "print(\"Pérdida en el conjunto de prueba:\", test_loss)\n",
    "print(\"Recall en el conjunto de prueba:\", test_recall)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0f6c3ae3",
   "metadata": {},
   "source": [
    "### Función de pérdida para el modelo de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "id": "14d5ad46",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.425575Z"
    }
   },
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "best_params = {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.005958432842192192, 'learning_rate_init': 0.0001422171191037891}\n",
    "\n",
    "best_model = MLPClassifier(**best_params, max_iter=200, warm_start=True)\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(200):  # Establece el número de épocas\n",
    "    best_model.partial_fit(X_train, y_train_clasification, classes=np.unique(y_train_clasification))\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de entrenamiento\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    train_loss = log_loss(y_train_clasification, best_model.predict_proba(X_train))\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_loss = log_loss(y_test_clasification, best_model.predict_proba(X_test))\n",
    "    val_loss_history.append(test_loss)\n",
    "\n",
    "# Graficar la pérdida durante el entrenamiento\n",
    "epochs = range(1, len(train_loss_history) + 1)\n",
    "plt.plot(epochs, train_loss_history, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_history, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b98ebdb2",
   "metadata": {},
   "source": [
    "### Diferencias entre las redes neuronales y los modelos de regresión lineal y logística:\n",
    "\n",
    "Las redes neuronales son modelos más complejos y adaptativos en comparación con los modelos de regresión lineal y logística. Tienen la capacidad de modelar relaciones no lineales complejas, lo que las hace ideales para problemas donde la simplicidad de las regresiones lineal y logística no es suficiente. Sin embargo, esta mayor complejidad y adaptabilidad viene con el costo de mayores tiempos de procesamiento y la necesidad de más recursos computacionales. Por otro lado, los modelos de regresión lineal y logística son más simples, rápidos de entrenar y evaluar, y son adecuados para problemas con relaciones lineales o para tareas de clasificación binaria con interpretabilidad directa de los coeficientes del modelo. La elección entre estos modelos depende de la naturaleza del problema, la complejidad de los datos y los recursos disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b83e6",
   "metadata": {},
   "source": [
    "### Comparación de modelos\n",
    "\n",
    "Para los modelos de regresión, utilizamos el R² como métrica de comparación, encontrando que la mayoría arrojaron resultados muy similares: 0.17 en entrenamiento y 0.19 en prueba. Sin embargo, al emplear redes neuronales con optimización mediante Optuna, logramos mejorar este valor a 0.29. En cuanto a los modelos de clasificación, utilizamos el recall como métrica principal. Las redes neuronales con optimización de hiperparámetros alcanzaron una precisión de 0.84, indicando un buen desempeño en la identificación de las clases positivas. Esto se debe a que una red neuronal con una sola neurona en la capa de salida puede actuar de manera similar a una regresión logística."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.426969Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.to_csv('train.csv', index=False)",
   "id": "a08e6d8d1ddc94c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T23:17:15.428302Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ff2b375a6a6c5efb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
